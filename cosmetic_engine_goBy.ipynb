{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000001_1.jpg', '000002_3.jpg', '000003_2.jpg', '000004_4.jpg', '000005_2.jpg', '000006_4.jpg', '000007_4.jpg', '000008_1.jpg', '000009_2.jpg', '000010_2.jpg', '000011_3.jpg', '000012_3.jpg', '000013_1.jpg', '000014_2.jpg', '000015_4.jpg', '000016_1.jpg', '000017_1.jpg', '000018_4.jpg', '000019_3.jpg', '000020_2.jpg', '000021_2.jpg', '000022_3.jpg', '000023_1.jpg', '000024_3.jpg', '000025_3.jpg', '000026_2.jpg', '000027_3.jpg', '000028_1.jpg', '000029_4.jpg', '000030_4.jpg', '000031_2.jpg', '000032_1.jpg', '000033_4.jpg', '000034_2.jpg', '000035_4.jpg', '000036_4.jpg', '000037_3.jpg', '000038_4.jpg', '000039_3.jpg', '000040_2.jpg', '000041_4.jpg', '000042_4.jpg', '000043_1.jpg', '000044_1.jpg', '000045_3.jpg', '000046_2.jpg', '000047_4.jpg', '000048_4.jpg', '000049_2.jpg', '000050_1.jpg', '000051_4.jpg', '000052_2.jpg', '000053_1.jpg', '000054_4.jpg', '000055_3.jpg', '000056_2.jpg', '000057_3.jpg', '000058_4.jpg', '000059_4.jpg', '000060_2.jpg', '000061_4.jpg', '000062_3.jpg', '000063_4.jpg', '000064_4.jpg', '000065_1.jpg', '000066_1.jpg', '000067_3.jpg', '000068_4.jpg', '000069_1.jpg', '000070_2.jpg', '000071_4.jpg', '000072_1.jpg', '000073_4.jpg', '000074_3.jpg', '000075_3.jpg', '000076_2.jpg', '000077_3.jpg', '000078_2.jpg', '000079_3.jpg', '000080_3.jpg', '000081_1.jpg', '000082_2.jpg', '000083_3.jpg', '000084_4.jpg', '000085_3.jpg', '000086_1.jpg', '000087_2.jpg', '000088_3.jpg', '000089_2.jpg', '000090_3.jpg', '000091_1.jpg', '000092_3.jpg', '000093_2.jpg', '000094_4.jpg', '000095_3.jpg', '000096_2.jpg', '000097_4.jpg', '000098_3.jpg', '000099_2.jpg', '000100_4.jpg', '000101_1.jpg', '000102_3.jpg', '000103_4.jpg', '000104_1.jpg', '000105_4.jpg', '000106_4.jpg', '000107_1.jpg', '000108_3.jpg', '000109_3.jpg', '000110_2.jpg', '000111_2.jpg', '000112_1.jpg', '000113_3.jpg', '000114_3.jpg', '000115_2.jpg', '000116_1.jpg', '000117_3.jpg', '000118_3.jpg', '000119_2.jpg', '000120_3.jpg', '000121_4.jpg', '000122_4.jpg', '000123_4.jpg', '000124_2.jpg', '000125_3.jpg', '000126_2.jpg', '000127_2.jpg', '000128_4.jpg']\n"
     ]
    }
   ],
   "source": [
    "#read all file names into a list\n",
    "pictureList = os.listdir(\"./FINAL_PICTURES/\")\n",
    "print pictureList[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from time import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_classes: 7\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Download the data, if not already on disk and load it as numpy arrays\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "# for machine learning we use the 2 data directly (as relative pixel\n",
    "# positions info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples: %d\" % n_samples)\n",
    "print(\"n_features: %d\" % n_features)\n",
    "print(\"n_classes: %d\" % n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Split into a training set and a test set using a stratified k fold\n",
    "\n",
    "# split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 150 eigenfaces from 966 faces\n",
      "done in 0.259s\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.024s\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
    "# dataset): unsupervised feature extraction / dimensionality reduction\n",
    "n_components = 150\n",
    "\n",
    "print(\"Extracting the top %d eigenfaces from %d faces\"\n",
    "      % (n_components, X_train.shape[0]))\n",
    "t0 = time()\n",
    "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "done in 13.455s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.005, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Train a SVM classification model\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting people's names on the test set\n",
      "done in 0.046s\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       0.86      0.46      0.60        13\n",
      "     Colin Powell       0.80      0.87      0.83        60\n",
      "  Donald Rumsfeld       0.94      0.63      0.76        27\n",
      "    George W Bush       0.83      0.98      0.90       146\n",
      "Gerhard Schroeder       0.95      0.80      0.87        25\n",
      "      Hugo Chavez       0.89      0.53      0.67        15\n",
      "       Tony Blair       0.97      0.81      0.88        36\n",
      "\n",
      "      avg / total       0.86      0.85      0.85       322\n",
      "\n",
      "[[  6   2   0   5   0   0   0]\n",
      " [  1  52   0   6   0   1   0]\n",
      " [  0   2  17   8   0   0   0]\n",
      " [  0   3   0 143   0   0   0]\n",
      " [  0   1   0   3  20   0   1]\n",
      " [  0   3   0   3   1   8   0]\n",
      " [  0   2   1   4   0   0  29]]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Quantitative evaluation of the model quality on the test set\n",
    "\n",
    "print(\"Predicting people's names on the test set\")\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Qualitative evaluation of the predictions using matplotlib\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the result of the prediction on a portion of the test set\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "                     for i in range(y_pred.shape[0])]\n",
    "\n",
    "plot_gallery(X_test, prediction_titles, h, w)\n",
    "\n",
    "# plot the gallery of the most significative eigenfaces\n",
    "\n",
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
